# <center> UDACITY Data Analysis Nanodegree </center> 
## <center> Project:- Visualizing FordGoBike Data</center>
#### Grant Patience, 16th September 2019


# Introduction
## Investigation Overview

> In this data analyis of the Ford GoBike data, we want to investigate common customer behaviors and demographics, such as peak usage times, and the effect of different behavioural patterns affect usage such as user type, gender, and age. 

## Dataset Overview

> Bay Wheels is a regional public bicycle sharing system in the San Francisco Bay Area, California operated by Motivate (a company based in New York City that operates bicycle sharing systems in the United States), in a partnership with the Metropolitan Transportation Commission and the Bay Area Air Quality Management District.
>
>Beginning operation in August 2013 as Bay Area Bike Share, the Bay Wheels system currently has over 2,600 bicycles in 262 stations across San Francisco, East Bay and San Jose. On June 28, 2017, the system officially re-launched as Ford GoBike in a partnership with Ford Motor Company.
>
>After Motivate's acquisition by Lyft, the system was subsequently renamed to Bay Wheels in June 2019.[5] The system is expected to expand to 7,000 bicycles around 540 stations in San Francisco, Oakland, Berkeley, Emeryville, and San Jose. Bay Wheels is the first regional and large-scale bicycle sharing system deployed in California and on the West Coast of the United States.
The data can be found [here](https://www.lyft.com/bikes/bay-wheels/system-data)

## Project Details
## 1.1 Outline of Steps <a class="anchor" id="outline"></a>
- We state what [resources](#Resources) are available to us and in [this](#Problemunderstanding) section we discuss what it is we wish to achieve, 
- We decide which [Questions](#QA) we want to ask of the data 
- We will [Gather the Data ](#DataGather) that we need 
- Import the data into Python to perform some initial [Understanding of the data](#Describedata) to help us understand the data, and [Assess Data Quality](#Verifydataquality) and perform any resolve any [Data Cleansing](#datacleansing).
- Perform [Exploratory Data Analysis](#eda) where we will research the answers to our questions
- Create visualisations to aid exploration and research 
- Draw our [Conclusion](#conclusion) based on the data and communicate our findings

## 1.1 Outline of Steps 
- We state what [resources](#Resources) are available to us and in [this](#Problemunderstanding) section we discuss what it is we wish to achieve, 
- We decide which [Questions](#QA) we want to ask of the data 
- We will [Gather the Data ](#DataGather) that we need 
- Import the data into Python to perform some initial [Understanding of the data](#Describedata) to help us understand the data, and [Assess Data Quality](#Verifydataquality) and perform any resolve any [Data Cleansing](#datacleansing).
- Perform [Exploratory Data Analysis](#eda) where we will research the answers to our questions
- Create visualisations to aid exploration and research
- Draw our [Conclusion](#conclusion) based on the data and communicate our findings

## What are the desired outputs of the project?
 
 - Accurate project submission:
 
 > - Ensure you meet specifications for all items in the Project Rubric. Your project "meets specifications" only if it meets specifications for all of the criteria.

